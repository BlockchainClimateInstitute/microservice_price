{"cells":[{"cell_type":"markdown","source":["# Batch Predict\nThis notebook performs batch inference using the pre-trained, registered mlflow model. Use the **bci-avm-dask** cluster with the **Train** notebook\nto see the model training.\n\n\n<p align=\"center\">\n<img width=25% src=\"https://blockchainclimate.org/wp-content/uploads/2020/11/cropped-BCI_Logo_LR-400x333.png\" alt=\"bciAVM\" height=\"300\"/>\n</p>\n\n[![PyPI](https://badge.fury.io/py/bciavm.svg?maxAge=2592000)](https://badge.fury.io/py/bciavm)\n[![PyPI Stats](https://img.shields.io/badge/bciavm-avm-blue)](https://pypistats.org/packages/bciavm)\n\n\nThis notebook contains code to take a `mlflow` registered model and distribute its work with a `Dask` cluster. \n<table>\n    <tr>\n        <td>\n            <img width=25% src=\"https://saturn-public-assets.s3.us-east-2.amazonaws.com/example-resources/dask.png\" width=\"300\">\n        </td>\n    </tr>\n</table>\n\nThe Blockchain & Climate Institute (BCI) is a progressive think tank providing leading expertise in the deployment of emerging technologies for climate and sustainability actions. \n\nAs an international network of scientific and technological experts, BCI is at the forefront of innovative efforts, enabling technology transfers, to create a sustainable and clean global future.\n\n# Automated Valuation Model (AVM) \n\n### About\nAVM is a term for a service that uses mathematical modeling combined with databases of existing properties and transactions to calculate real estate values. \nThe majority of automated valuation models (AVMs) compare the values of similar properties at the same point in time. \nMany appraisers, and even Wall Street institutions, use this type of model to value residential properties. (see [What is an AVM](https://www.investopedia.com/terms/a/automated-valuation-model.asp) Investopedia.com)\n\nFor more detailed info about the AVM, please read the **About** paper found here `resources/2021-BCI-AVM-About.pdf`.\n\n### Valuation Process\n<img src=\"resources/valuation_process.png\" height=\"360\" >\n\n**Key Functionality**\n\n* **Supervised algorithms** \n* **Tree-based & deep learning algorithms** \n* **Feature engineering derived from small clusters of similar properties** \n* **Ensemble (value blending) approaches** \n\n### Set the required AWS Environment Variables\n```shell\nexport ACCESS_KEY=YOURACCESS_KEY\nexport SECRET_KEY=YOURSECRET_KEY\nexport BUCKET_NAME=bci-transition-risk-data\nexport TABLE_DIRECTORY=/dbfs/FileStore/tables/\n```\n\n### Next Steps\nRead more about bciAVM on our [documentation page](https://blockchainclimate.org/thought-leadership/#blog):\n\n### How does it relate to BCI Risk Modeling?\n<img src=\"resources/bci_flowchart_2.png\" height=\"280\" >\n\n\n### Technical & financial support for development provided by:\n<a href=\"https://www.gcode.ai\">\n    <img width=15% src=\"https://staticfiles-img.s3.amazonaws.com/avm/gcode_logo.png\" alt=\"GCODE.ai\"  height=\"25\"/>\n</a>\n\n\n### Install [from PyPI](https://pypi.org/project/bciavm/)\n```shell\npip install bciavm\n```\n\nThis notebook covers the following steps:\n- Import data from your local machine into the Databricks File System (DBFS)\n- Download data from s3\n- Train a machine learning models (or more technically, multiple models in a stacked pipeline) on the dataset\n- Register the model in MLflow"],"metadata":{}},{"cell_type":"markdown","source":["<hr>\n\n## Environment Setup\n\nIn addition to the `bciavm` package, install the following additional non-builtin libraries:\n\n* [dask-ml](https://github.com/dask/dask-ml)"],"metadata":{}},{"cell_type":"code","source":["import os\nimport time\nimport uuid\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport dask.dataframe as dd\nimport dask\nfrom dask.distributed import Client\nimport mlflow\nfrom mlflow.tracking import MlflowClient\nimport bciavm\nimport re\nfrom urllib.request import urlopen\nimport zipfile\nfrom io import BytesIO\nfrom dask.distributed import wait\nimport shutil\nimport gc"],"metadata":{"execution":{"iopub.status.busy":"2021-06-08T22:05:11.027523Z","iopub.execute_input":"2021-06-08T22:05:11.027802Z","shell.execute_reply.started":"2021-06-08T22:05:11.027735Z","shell.execute_reply":"2021-06-08T22:05:12.954165Z","iopub.status.idle":"2021-06-08T22:05:12.954774Z"}},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2021-06-15 18:34:37,089 featuretools - WARNING    Featuretools failed to load plugin nlp_primitives from library nlp_primitives. For a full stack trace, set logging to debug.\n</div>"]}}],"execution_count":3},{"cell_type":"code","source":["# shutil.rmtree('/dbfs/FileStore/tables/avm_output/')\n_date = str(datetime.now())\n# os.mkdir('/dbfs/FileStore/tables/avm/avm_output_'+_date)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["spark.read.format(\"parquet\").load(\"mnt/bct-transition-risk-data/epc_data/byLocation/DateRun_2021-02-07/{*}/domestic/certificates\").createOrReplaceTempView(\"EPCData\")"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":5},{"cell_type":"code","source":["%sql\nSELECT *\nFROM EPCData"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["spark.createDataFrame(pd.read_csv(\"/dbfs/FileStore/tables/ukpostcodes.csv\")).createOrReplaceTempView(\"sqlPostcodeLonLat\")\nspark.createDataFrame(pd.read_csv(\"/dbfs/FileStore/tables/postcode_outcodes.csv\")).createOrReplaceTempView(\"sqlOutcodeLonLat\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["%sql\n\nCREATE OR REPLACE TEMPORARY VIEW EPCDataFeatures AS\nSELECT BUILDING_REFERENCE_NUMBER AS unit_indx\n,t1.POSTCODE\n,SPLIT(t1.POSTCODE, \" \")[0] AS POSTCODE_OUTCODE\n,POSTTOWN AS POSTTOWN_e\n,PROPERTY_TYPE AS PROPERTY_TYPE_e\n,TOTAL_FLOOR_AREA AS TOTAL_FLOOR_AREA_e\n,NUMBER_HEATED_ROOMS AS NUMBER_HEATED_ROOMS_e\n,FLOOR_LEVEL AS FLOOR_LEVEL_e\n,CASE WHEN t3.latitude IS NOT NULL THEN t3.latitude ELSE t4.latitude END AS Latitude_m\n,CASE WHEN t3.longitude IS NOT NULL THEN t3.longitude ELSE t4.longitude END AS Longitude_m\n,CASE WHEN CAST (RIGHT(LEFT(t1.POSTCODE, 2), 1) AS INT) IS NULL THEN LEFT(t1.POSTCODE, 2) ELSE LEFT(t1.POSTCODE, 1) END AS POSTCODE_AREA\n,ROW_NUMBER() OVER (PARTITION BY BUILDING_REFERENCE_NUMBER ORDER BY INSPECTION_DATE DESC) AS rownum\nFROM EPCData t1\nLEFT JOIN sqlPostcodeLonLat t3 ON t1.POSTCODE = t3.Postcode\nLEFT JOIN sqlOutcodeLonLat t4 ON SPLIT(t1.POSTCODE, \" \")[0] = t4.postcode;\n\nDROP TABLE IF EXISTS epcHomesToScore;\n\nCREATE TABLE epcHomesToScore AS\nSELECT unit_indx\n,POSTCODE\n,POSTCODE_OUTCODE\n,POSTTOWN_e\n,PROPERTY_TYPE_e\n,TOTAL_FLOOR_AREA_e\n,NUMBER_HEATED_ROOMS_e\n,FLOOR_LEVEL_e\n,Latitude_m\n,Longitude_m\n,POSTCODE_AREA\nFROM EPCDataFeatures\nWHERE rownum = 1;\n\nSELECT *\nFROM epcHomesToScore"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["data = spark.sql(\"SELECT * FROM epcHomesToScore\").toPandas()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["MLFLOW_TRACKING_URI = os.environ[\"MLFLOW_TRACKING_URI\"]\nmlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\nmlflow.set_experiment('/Users/mike.casale@blockchainclimate.org/Experiments/batch-predict')"],"metadata":{"execution":{"iopub.status.busy":"2021-06-08T22:05:12.955759Z","iopub.execute_input":"2021-06-08T22:05:12.955939Z","shell.execute_reply.started":"2021-06-08T22:05:12.955917Z","shell.execute_reply":"2021-06-08T22:05:14.775405Z","iopub.status.idle":"2021-06-08T22:05:14.775943Z"}},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":10},{"cell_type":"code","source":["#TODO: merge w/ SQL preprocessing (above step)\ndata = bciavm.utils.bci_utils.preprocess_data(data.rename({'Postcode':'POSTCODE'},axis=1), \n                                              drop_outlier=False, \n                                              split_data=False)\n\ndata.to_csv('/dbfs/FileStore/tables/avm/epcPrice.csv')\ndata"],"metadata":{"execution":{"iopub.status.busy":"2021-06-08T22:05:14.782160Z","iopub.execute_input":"2021-06-08T22:05:14.782412Z","shell.execute_reply.started":"2021-06-08T22:05:14.782380Z","shell.execute_reply":"2021-06-08T22:06:15.700567Z","iopub.status.idle":"2021-06-08T22:06:15.701232Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":["input_example=data.dropna().sample(10)\ninput_example.dtypes"],"metadata":{"execution":{"iopub.status.busy":"2021-06-08T22:06:15.702105Z","iopub.execute_input":"2021-06-08T22:06:15.702283Z","shell.execute_reply.started":"2021-06-08T22:06:15.702261Z","shell.execute_reply":"2021-06-08T22:06:21.707669Z","iopub.status.idle":"2021-06-08T22:06:21.708333Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":["c = Client('127.0.0.1:8786')\n\nprint('waiting for workers...')\nc.wait_for_workers(1)\n\nprint('done...')"],"metadata":{"execution":{"iopub.status.busy":"2021-06-08T22:06:48.596644Z","iopub.execute_input":"2021-06-08T22:06:48.596824Z","shell.execute_reply.started":"2021-06-08T22:06:48.596803Z","shell.execute_reply":"2021-06-08T22:16:02.101310Z","iopub.status.idle":"2021-06-08T22:16:02.102081Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":["def mlflow_load_model(pred_type=None, model_name='avm', model_version='Production'):\n    \"\"\"Loads model from mlflow.\n\n    Returns:\n        mlflow.pyfunc loaded model\n    \"\"\"\n    if pred_type == 'conf':\n      model_name='avm-conf'\n      \n    return mlflow.pyfunc.load_model(\n        model_uri=f\"models:/{model_name}/{model_version}\"\n    )   \n  \nmodel = mlflow_load_model()\nconf_model = mlflow_load_model(pred_type='conf')"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["model.predict(input_example)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["conf_model.predict(input_example)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["\ndef get_unics(data=None):\n    \"\"\"Gets sample=1 for each unique combination of POSTCODE_AREA + PROPERTY_TYPE_e\n       This is used to compute the confidence for all other properties which share \n       the POSTCODE_AREA + PROPERTY_TYPE_e + NUMBER_HEATED_ROOMS_e + FLOOR_LEVEL_e combination\n\n    Returns:\n        pd.dataframe \n    \"\"\"\n    \n    try: os.mkdir('/dbfs/FileStore/tables/avm/avm_conf/')\n    except:pass\n    \n    \n    if data is None:\n        data = pd.read_csv('/dbfs/FileStore/tables/avm/epcPrice.csv')\n    \n    df = pd.DataFrame({})\n    data['key'] = data['POSTCODE_AREA'] + data['PROPERTY_TYPE_e']\n    unics = data['key'].unique()\n    for u in unics:\n      df = df.append(data[data['key']==u].sample(1))\n    \n    return df\n\ndef load_model():\n    return bciavm.pipelines.RegressionPipeline.load('/dbfs/FileStore/artifacts/avm_pipeline_'+str(bciavm.__version__)+'.pkl')\n\ndef predict(X, model, columns=['avm']):\n    \"\"\"Main prediction logic\n    Returns:\n        pd.dataframe \n    \"\"\"    \n    X['key'] = X['POSTCODE_AREA'] + X['PROPERTY_TYPE_e'] \n    unit_index = X['unit_indx'].values\n    key = X['key'].values\n    resp = pd.DataFrame(model.predict(X).values, columns=columns)\n    resp['unit_indx'] = unit_index\n    resp['key'] = key\n    del X\n    gc.collect()\n    return resp\n    \ndef save(preds):\n    filename='/dbfs/FileStore/tables/avm/avm_output/avm_output_'+str(datetime.now())+'.parquet.gzip'\n    return preds.to_parquet(filename, compression='gzip')\n\ndef f(ct):\n    for x in pd.read_csv('/dbfs/FileStore/tables/avm/epcPrice.csv', chunksize=500000):\n        ct = ct + 1\n        start_time = datetime.now()\n        model = load_model()\n        preds = predict(x, model)\n        save(preds)\n        end_time = datetime.now()\n        del x\n        del preds\n        model = None\n        gc.collect()\n        print('Duration: {}'.format(end_time - start_time), ct)\n\n    return ct\n  \ntry: os.mkdir('/dbfs/FileStore/tables/avm/avm_output/')\nexcept:pass"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["ct = 0\ndask.compute(f(ct))"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["preds = dd.read_parquet('/dbfs/FileStore/tables/avm/avm_output/*.parquet.gzip', compression='gzip')\npreds = preds.compute()\npreds = preds.drop_duplicates('unit_indx')\npreds"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[2]: </div>"]}},{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avm</th>\n      <th>unit_indx</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>151990.171875</td>\n      <td>0</td>\n      <td>PLHouse</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>193218.078125</td>\n      <td>1</td>\n      <td>NRFlat</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>341111.875000</td>\n      <td>2</td>\n      <td>SMHouse</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>280344.187500</td>\n      <td>3</td>\n      <td>SOHouse</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>172852.671875</td>\n      <td>4</td>\n      <td>LHouse</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>216117</th>\n      <td>307351.437500</td>\n      <td>15716117</td>\n      <td>BNHouse</td>\n    </tr>\n    <tr>\n      <th>216118</th>\n      <td>154638.515625</td>\n      <td>15716118</td>\n      <td>COHouse</td>\n    </tr>\n    <tr>\n      <th>216119</th>\n      <td>532772.562500</td>\n      <td>15716119</td>\n      <td>WRHouse</td>\n    </tr>\n    <tr>\n      <th>216120</th>\n      <td>108124.789062</td>\n      <td>15716120</td>\n      <td>BHouse</td>\n    </tr>\n    <tr>\n      <th>216121</th>\n      <td>233568.078125</td>\n      <td>15716121</td>\n      <td>MKHouse</td>\n    </tr>\n  </tbody>\n</table>\n<p>15716122 rows × 3 columns</p>\n</div>"]}}],"execution_count":19},{"cell_type":"code","source":["#Get all unique POSTCODE_AREA + PROPERTY_TYPE_e\ntry:\n  unics = get_unics(data=data)\nexcept:\n  unics = get_unics()\nunics"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["try: os.mkdir('/dbfs/FileStore/tables/avm/avm_conf')\nexcept: pass\n\nunics.to_parquet('/dbfs/FileStore/tables/avm/avm_conf/unics.parquet.gzip', compression='gzip')"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["unics = dd.read_parquet('/dbfs/FileStore/tables/avm/avm_conf/unics.parquet.gzip', compression='gzip')\nunics = unics.compute()\nunics"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: </div>"]}},{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>unit_indx</th>\n      <th>POSTCODE</th>\n      <th>POSTCODE_OUTCODE</th>\n      <th>POSTCODE_AREA</th>\n      <th>POSTTOWN_e</th>\n      <th>PROPERTY_TYPE_e</th>\n      <th>TOTAL_FLOOR_AREA_e</th>\n      <th>NUMBER_HEATED_ROOMS_e</th>\n      <th>FLOOR_LEVEL_e</th>\n      <th>Latitude_m</th>\n      <th>Longitude_m</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11013509</th>\n      <td>11013509</td>\n      <td>11013509</td>\n      <td>PL7 2GT</td>\n      <td>PL7</td>\n      <td>PL</td>\n      <td>PLYMOUTH</td>\n      <td>House</td>\n      <td>46.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>50.389810</td>\n      <td>-4.023573</td>\n      <td>PLHouse</td>\n    </tr>\n    <tr>\n      <th>6151308</th>\n      <td>6151308</td>\n      <td>6151308</td>\n      <td>NR17 2EH</td>\n      <td>NR17</td>\n      <td>NR</td>\n      <td>ATTLEBOROUGH</td>\n      <td>Flat</td>\n      <td>63.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>52.516199</td>\n      <td>1.013926</td>\n      <td>NRFlat</td>\n    </tr>\n    <tr>\n      <th>4720629</th>\n      <td>4720629</td>\n      <td>4720629</td>\n      <td>SM6 8QB</td>\n      <td>SM6</td>\n      <td>SM</td>\n      <td>WALLINGTON</td>\n      <td>House</td>\n      <td>159.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>51.360429</td>\n      <td>-0.145775</td>\n      <td>SMHouse</td>\n    </tr>\n    <tr>\n      <th>10982040</th>\n      <td>10982040</td>\n      <td>10982040</td>\n      <td>SO16 0BP</td>\n      <td>SO16</td>\n      <td>SO</td>\n      <td>SOUTHAMPTON</td>\n      <td>House</td>\n      <td>64.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>50.939200</td>\n      <td>-1.466033</td>\n      <td>SOHouse</td>\n    </tr>\n    <tr>\n      <th>11356452</th>\n      <td>11356452</td>\n      <td>11356452</td>\n      <td>L33 1SA</td>\n      <td>L33</td>\n      <td>L</td>\n      <td>LIVERPOOL</td>\n      <td>House</td>\n      <td>86.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>53.497772</td>\n      <td>-2.876649</td>\n      <td>LHouse</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7597236</th>\n      <td>7597236</td>\n      <td>7597236</td>\n      <td>RM3 7TZ</td>\n      <td>RM3</td>\n      <td>RM</td>\n      <td>ROMFORD</td>\n      <td>Park home</td>\n      <td>47.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>51.619894</td>\n      <td>0.215145</td>\n      <td>RMPark home</td>\n    </tr>\n    <tr>\n      <th>14140014</th>\n      <td>14140014</td>\n      <td>14140014</td>\n      <td>NE49 0QN</td>\n      <td>NE49</td>\n      <td>NE</td>\n      <td>HALTWHISTLE</td>\n      <td>Park home</td>\n      <td>63.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>54.922310</td>\n      <td>-2.471466</td>\n      <td>NEPark home</td>\n    </tr>\n    <tr>\n      <th>13656903</th>\n      <td>13656903</td>\n      <td>13656903</td>\n      <td>AL9 7HZ</td>\n      <td>AL9</td>\n      <td>AL</td>\n      <td>HATFIELD</td>\n      <td>Park home</td>\n      <td>61.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>51.739307</td>\n      <td>-0.211835</td>\n      <td>ALPark home</td>\n    </tr>\n    <tr>\n      <th>10593794</th>\n      <td>10593794</td>\n      <td>10593794</td>\n      <td>DG4 6NB</td>\n      <td>DG4</td>\n      <td>DG</td>\n      <td>SANQUHAR</td>\n      <td>Maisonette</td>\n      <td>160.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>55.387299</td>\n      <td>-4.003707</td>\n      <td>DGMaisonette</td>\n    </tr>\n    <tr>\n      <th>14872160</th>\n      <td>14872160</td>\n      <td>14872160</td>\n      <td>lE2 7PA</td>\n      <td>lE2</td>\n      <td>lE</td>\n      <td>LEICESTER</td>\n      <td>Flat</td>\n      <td>67.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>lEFlat</td>\n    </tr>\n  </tbody>\n</table>\n<p>512 rows × 13 columns</p>\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["%%time\n\nprint('Building a dask dataframe...')\nddf = dd.from_pandas(unics, npartitions=8)\nX_test_arr = dask.persist(ddf)\n_ = wait(X_test_arr)\nX_test_arr = X_test_arr[0]\n\ncols=['unit_id','avm','avm_lower','avm_upper','conf','ts','latest_production_version','latest_staging_version']\n\nprint('Predicting...')\nconfs = X_test_arr.map_partitions(\n        predict, \n        model=conf_model,\n        columns=cols\n).compute()\n\nconfs.to_parquet('/dbfs/FileStore/tables/avm/avm_conf/confs_output.parquet.gzip', compression='gzip')\nconfs"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["confs = dd.read_parquet('/dbfs/FileStore/tables/avm/avm_conf/confs_output.parquet.gzip', compression='gzip')\nconfs = confs.compute()\nconfs"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[3]: </div>"]}},{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unit_id</th>\n      <th>avm</th>\n      <th>avm_lower</th>\n      <th>avm_upper</th>\n      <th>conf</th>\n      <th>ts</th>\n      <th>latest_production_version</th>\n      <th>latest_staging_version</th>\n      <th>unit_indx</th>\n      <th>key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>48571</td>\n      <td>357471.0</td>\n      <td>265926.0</td>\n      <td>439252.0</td>\n      <td>0.743909</td>\n      <td>1623744165.489511</td>\n      <td>29</td>\n      <td>None</td>\n      <td>48571</td>\n      <td>GUBungalow</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>60051</td>\n      <td>68495.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1623744171.328713</td>\n      <td>29</td>\n      <td>None</td>\n      <td>60051</td>\n      <td>NRPark home</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>139243</td>\n      <td>243433.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1623744174.346069</td>\n      <td>29</td>\n      <td>None</td>\n      <td>139243</td>\n      <td>BAPark home</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>158227</td>\n      <td>250987.0</td>\n      <td>204725.0</td>\n      <td>412575.0</td>\n      <td>NaN</td>\n      <td>1623744178.011655</td>\n      <td>29</td>\n      <td>None</td>\n      <td>158227</td>\n      <td>WFHouse</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>207589</td>\n      <td>151513.0</td>\n      <td>122096.0</td>\n      <td>200466.0</td>\n      <td>0.676902</td>\n      <td>1623744184.665239</td>\n      <td>29</td>\n      <td>None</td>\n      <td>207589</td>\n      <td>BHouse</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>15506551</td>\n      <td>196848.0</td>\n      <td>168859.0</td>\n      <td>255675.0</td>\n      <td>0.701156</td>\n      <td>1623744778.547672</td>\n      <td>29</td>\n      <td>None</td>\n      <td>15506551</td>\n      <td>EXHouse</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>15565619</td>\n      <td>165163.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1623744784.160804</td>\n      <td>29</td>\n      <td>None</td>\n      <td>15565619</td>\n      <td>HGPark home</td>\n    </tr>\n    <tr>\n      <th>61</th>\n      <td>15616418</td>\n      <td>58388.0</td>\n      <td>32524.0</td>\n      <td>123120.0</td>\n      <td>NaN</td>\n      <td>1623744787.068207</td>\n      <td>29</td>\n      <td>None</td>\n      <td>15616418</td>\n      <td>DHFlat</td>\n    </tr>\n    <tr>\n      <th>62</th>\n      <td>15689393</td>\n      <td>223733.0</td>\n      <td>199122.0</td>\n      <td>265645.0</td>\n      <td>0.812672</td>\n      <td>1623744792.967538</td>\n      <td>29</td>\n      <td>None</td>\n      <td>15689393</td>\n      <td>RGHouse</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>15696716</td>\n      <td>855930.0</td>\n      <td>695100.0</td>\n      <td>1109218.0</td>\n      <td>0.704078</td>\n      <td>1623744798.782275</td>\n      <td>29</td>\n      <td>None</td>\n      <td>15696716</td>\n      <td>SWHouse</td>\n    </tr>\n  </tbody>\n</table>\n<p>512 rows × 10 columns</p>\n</div>"]}}],"execution_count":24},{"cell_type":"code","source":["def correct(predictions, conf_min=0.5):\n    predictions[ 'avm' ] = round(predictions[ 'avm' ].astype(float), 0)\n    predictions[ 'conf' ] = round(predictions[ 'conf' ].astype(float), 2)\n    try :\n      predictions[ 'avm' ] = np.where(predictions[ 'avm' ].astype(float) < 0.0, np.nan, predictions[ 'avm' ].astype(float))\n    except :\n      pass\n    try :\n      predictions[ 'avm_lower' ] = np.where(predictions[ 'avm_lower' ].astype(float) < 0.0, np.nan, predictions[ 'avm_lower' ].astype(float))\n    except :\n      pass\n    try :\n      predictions[ 'avm_upper' ] = np.where(predictions[ 'avm_upper' ].astype(float) < 0.0, np.nan, predictions[ 'avm_upper' ].astype(float))\n    except :\n      pass\n    try :\n      predictions[ 'avm_lower' ] = np.where(predictions[ 'avm_lower' ].astype(float) > predictions[ 'avm' ].astype(float), np.nan,\n                                   predictions[ 'avm_lower' ].astype(float))\n    except :\n      pass\n    try :\n      predictions[ 'avm_upper' ] = np.where(predictions[ 'avm_upper' ].astype(float) < predictions[ 'avm' ].astype(float), np.nan,\n                                   predictions[ 'avm_upper' ].astype(float))\n    except :\n      pass\n    try :\n      predictions.name = self.input_target_name\n    except :\n      pass\n\n    try :\n      predictions[ 'conf' ] = np.where(predictions[ 'conf' ].astype(float) < conf_min, '< 0.5',\n                                   predictions[ 'conf' ].astype(float))\n    except :\n      pass\n    \n    predictions[ 'conf' ] = np.where(np.isnan(predictions[ 'avm_upper' ]), np.nan, predictions[ 'conf' ])\n    predictions[ 'conf' ] = np.where(np.isnan(predictions[ 'avm_lower' ]), np.nan, predictions[ 'conf' ])\n    return predictions"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":25},{"cell_type":"code","source":["combined = preds.merge(confs.drop(['unit_indx', 'avm'],axis=1), on='key', how='left')\nlower = combined['avm_lower'] / combined['avm'] - 1.0  \nupper = combined['avm_upper'] / combined['avm'] - 1.0\ncombined['avm_upper'] = upper\ncombined['avm_lower'] = lower\n\ncombined[ 'avm_lower' ] = round(\n            combined[ 'avm' ].astype(float) + combined[ 'avm' ].astype(float) * combined[ 'avm_lower' ].astype(float),\n            0)\ncombined[ 'avm_upper' ] = round(\n            combined[ 'avm' ].astype(float) + combined[ 'avm' ].astype(float) * combined[ 'avm_upper' ].astype(float),\n            0)\n\ncombined['fsd'] = np.where((combined[ 'avm' ] - combined[ 'avm_lower' ]) >= (combined[ 'avm_upper' ] - combined[ 'avm' ]), combined[ 'avm' ] - combined[ 'avm_lower' ], combined[ 'avm_upper' ] - combined[ 'avm' ])\n\nconf = 1.0 - combined['fsd'] / combined[ 'avm' ]\ncombined['conf'] = conf\ncombined = correct(combined, conf_min=0.5)\ncombined = combined.drop(['latest_staging_version', 'unit_id'], axis=1)\ncombined['conf'] = combined['conf'].fillna('< 0.5')\ncombined['avm_lower'] = np.where(np.isnan(combined['avm_lower']), combined['avm'] - combined['fsd'], combined['avm_lower'])\ncombined['avm_upper'] = np.where(np.isnan(combined['avm_upper']), combined['avm'] + combined['fsd'], combined['avm_upper'])\ncombined['avm_lower'] = np.where(combined['avm_lower'] < 0, 0.0, combined['avm_lower'])\ncombined = combined.drop('key',axis=1)\ncombined['avm_upper'] = round(combined['avm_upper'], 0)\ncombined['avm_lower'] = round(combined['avm_lower'], 0)\ncombined['fsd'] = round(combined['fsd'], 0)\ncombined"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: </div>"]}},{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>avm</th>\n      <th>unit_indx</th>\n      <th>avm_lower</th>\n      <th>avm_upper</th>\n      <th>conf</th>\n      <th>ts</th>\n      <th>latest_production_version</th>\n      <th>fsd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>151990.0</td>\n      <td>0</td>\n      <td>117895.0</td>\n      <td>180902.0</td>\n      <td>0.78</td>\n      <td>1623744632.342138</td>\n      <td>29</td>\n      <td>34095.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>193218.0</td>\n      <td>1</td>\n      <td>164335.0</td>\n      <td>244350.0</td>\n      <td>0.74</td>\n      <td>1623744483.552008</td>\n      <td>29</td>\n      <td>51132.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>341112.0</td>\n      <td>2</td>\n      <td>6714.0</td>\n      <td>675510.0</td>\n      <td>&lt; 0.5</td>\n      <td>1623744232.581653</td>\n      <td>29</td>\n      <td>334398.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>280344.0</td>\n      <td>3</td>\n      <td>150273.0</td>\n      <td>410415.0</td>\n      <td>&lt; 0.5</td>\n      <td>1623744615.831788</td>\n      <td>29</td>\n      <td>130071.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>172853.0</td>\n      <td>4</td>\n      <td>58294.0</td>\n      <td>287412.0</td>\n      <td>&lt; 0.5</td>\n      <td>1623744683.505588</td>\n      <td>29</td>\n      <td>114559.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>15716117</th>\n      <td>307351.0</td>\n      <td>15716117</td>\n      <td>0.0</td>\n      <td>677605.0</td>\n      <td>&lt; 0.5</td>\n      <td>1623744253.444732</td>\n      <td>29</td>\n      <td>370254.0</td>\n    </tr>\n    <tr>\n      <th>15716118</th>\n      <td>154639.0</td>\n      <td>15716118</td>\n      <td>0.0</td>\n      <td>410505.0</td>\n      <td>&lt; 0.5</td>\n      <td>1623744228.757267</td>\n      <td>29</td>\n      <td>255866.0</td>\n    </tr>\n    <tr>\n      <th>15716119</th>\n      <td>532773.0</td>\n      <td>15716119</td>\n      <td>233575.0</td>\n      <td>831971.0</td>\n      <td>&lt; 0.5</td>\n      <td>1623744359.778892</td>\n      <td>29</td>\n      <td>299198.0</td>\n    </tr>\n    <tr>\n      <th>15716120</th>\n      <td>108125.0</td>\n      <td>15716120</td>\n      <td>15784.0</td>\n      <td>200466.0</td>\n      <td>&lt; 0.5</td>\n      <td>1623744184.665239</td>\n      <td>29</td>\n      <td>92341.0</td>\n    </tr>\n    <tr>\n      <th>15716121</th>\n      <td>233568.0</td>\n      <td>15716121</td>\n      <td>193899.0</td>\n      <td>403383.0</td>\n      <td>&lt; 0.5</td>\n      <td>1623744782.232522</td>\n      <td>29</td>\n      <td>169815.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>15716122 rows × 8 columns</p>\n</div>"]}}],"execution_count":26},{"cell_type":"code","source":["_date = str(datetime.now().date())\n_date"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[7]: &#39;2021-06-15&#39;</div>"]}}],"execution_count":27},{"cell_type":"code","source":["combined.to_parquet('/dbfs/FileStore/tables/avm/final_output_'+_date+'.parquet.gzip', compression='gzip')"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":28},{"cell_type":"code","source":["spark_df = spark.createDataFrame(combined)\n\nspark_df.write.mode(\"overwrite\").saveAsTable(\"/dbfs/FileStore/tables/avm_output_\"+_date)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">ParseException</span>                            Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-724349529837620&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> spark_df <span class=\"ansi-blue-fg\">=</span> spark<span class=\"ansi-blue-fg\">.</span>createDataFrame<span class=\"ansi-blue-fg\">(</span>combined<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> \n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>spark_df<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>mode<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;overwrite&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;/dbfs/FileStore/tables/avm_output_&#34;</span><span class=\"ansi-blue-fg\">+</span>_date<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">saveAsTable</span><span class=\"ansi-blue-fg\">(self, name, format, mode, partitionBy, **options)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    869</span>         <span class=\"ansi-green-fg\">if</span> format <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">not</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    870</span>             self<span class=\"ansi-blue-fg\">.</span>format<span class=\"ansi-blue-fg\">(</span>format<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 871</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>saveAsTable<span class=\"ansi-blue-fg\">(</span>name<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    872</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    873</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.4</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">ParseException</span>: \nextraneous input &#39;/&#39; expecting {&#39;CLONE&#39;, &#39;COLLECT&#39;, &#39;CONVERT&#39;, &#39;COPY&#39;, &#39;COPY_OPTIONS&#39;, &#39;CREDENTIALS&#39;, &#39;DEEP&#39;, &#39;DELTA&#39;, &#39;ENCRYPTION&#39;, &#39;FILES&#39;, &#39;FORMAT_OPTIONS&#39;, &#39;HISTORY&#39;, &#39;OPTIMIZE&#39;, &#39;PATTERN&#39;, &#39;RESTORE&#39;, &#39;SAMPLE&#39;, &#39;SHALLOW&#39;, &#39;TIMESTAMP&#39;, &#39;VERSION&#39;, &#39;ZORDER&#39;, &#39;ADD&#39;, &#39;AFTER&#39;, &#39;ALL&#39;, &#39;ALTER&#39;, &#39;ANALYZE&#39;, &#39;AND&#39;, &#39;ANTI&#39;, &#39;ANY&#39;, &#39;ARCHIVE&#39;, &#39;ARRAY&#39;, &#39;AS&#39;, &#39;ASC&#39;, &#39;AT&#39;, &#39;AUTHORIZATION&#39;, &#39;BETWEEN&#39;, &#39;BOTH&#39;, &#39;BUCKET&#39;, &#39;BUCKETS&#39;, &#39;BY&#39;, &#39;CACHE&#39;, &#39;CASCADE&#39;, &#39;CASE&#39;, &#39;CAST&#39;, &#39;CHANGE&#39;, &#39;CHECK&#39;, &#39;CLEAR&#39;, &#39;CLUSTER&#39;, &#39;CLUSTERED&#39;, &#39;CODEGEN&#39;, &#39;COLLATE&#39;, &#39;COLLECTION&#39;, &#39;COLUMN&#39;, &#39;COLUMNS&#39;, &#39;COMMENT&#39;, &#39;COMMIT&#39;, &#39;COMPACT&#39;, &#39;COMPACTIONS&#39;, &#39;COMPUTE&#39;, &#39;CONCATENATE&#39;, &#39;CONSTRAINT&#39;, &#39;COST&#39;, &#39;CREATE&#39;, &#39;CROSS&#39;, &#39;CUBE&#39;, &#39;CURRENT&#39;, &#39;CURRENT_DATE&#39;, &#39;CURRENT_TIME&#39;, &#39;CURRENT_TIMESTAMP&#39;, &#39;CURRENT_USER&#39;, &#39;DATA&#39;, &#39;DATABASE&#39;, DATABASES, &#39;DBPROPERTIES&#39;, &#39;DEFINED&#39;, &#39;DELETE&#39;, &#39;DELIMITED&#39;, &#39;DESC&#39;, &#39;DESCRIBE&#39;, &#39;DFS&#39;, &#39;DIRECTORIES&#39;, &#39;DIRECTORY&#39;, &#39;DISTINCT&#39;, &#39;DISTRIBUTE&#39;, &#39;DIV&#39;, &#39;DROP&#39;, &#39;ELSE&#39;, &#39;END&#39;, &#39;ESCAPE&#39;, &#39;ESCAPED&#39;, &#39;EXCEPT&#39;, &#39;EXCHANGE&#39;, &#39;EXISTS&#39;, &#39;EXPLAIN&#39;, &#39;EXPORT&#39;, &#39;EXTENDED&#39;, &#39;EXTERNAL&#39;, &#39;EXTRACT&#39;, &#39;FALSE&#39;, &#39;FETCH&#39;, &#39;FIELDS&#39;, &#39;FILTER&#39;, &#39;FILEFORMAT&#39;, &#39;FIRST&#39;, &#39;FOLLOWING&#39;, &#39;FOR&#39;, &#39;FOREIGN&#39;, &#39;FORMAT&#39;, &#39;FORMATTED&#39;, &#39;FROM&#39;, &#39;FULL&#39;, &#39;FUNCTION&#39;, &#39;FUNCTIONS&#39;, &#39;GLOBAL&#39;, &#39;GRANT&#39;, &#39;GROUP&#39;, &#39;GROUPING&#39;, &#39;HAVING&#39;, &#39;IF&#39;, &#39;IGNORE&#39;, &#39;IMPORT&#39;, &#39;IN&#39;, &#39;INDEX&#39;, &#39;INDEXES&#39;, &#39;INNER&#39;, &#39;INPATH&#39;, &#39;INPUTFORMAT&#39;, &#39;INSERT&#39;, &#39;INTERSECT&#39;, &#39;INTERVAL&#39;, &#39;INTO&#39;, &#39;IS&#39;, &#39;ITEMS&#39;, &#39;JOIN&#39;, &#39;KEY&#39;, &#39;KEYS&#39;, &#39;LAST&#39;, &#39;LATERAL&#39;, &#39;LAZY&#39;, &#39;LEADING&#39;, &#39;LEFT&#39;, &#39;LIKE&#39;, &#39;LIMIT&#39;, &#39;LINES&#39;, &#39;LIST&#39;, &#39;LOAD&#39;, &#39;LOCAL&#39;, &#39;LOCATION&#39;, &#39;LOCK&#39;, &#39;LOCKS&#39;, &#39;LOGICAL&#39;, &#39;MACRO&#39;, &#39;MAP&#39;, &#39;MATCHED&#39;, &#39;MERGE&#39;, &#39;MSCK&#39;, &#39;NAMESPACE&#39;, &#39;NAMESPACES&#39;, &#39;NATURAL&#39;, &#39;NO&#39;, NOT, &#39;NULL&#39;, &#39;NULLS&#39;, &#39;OF&#39;, &#39;ON&#39;, &#39;ONLY&#39;, &#39;OPTION&#39;, &#39;OPTIONS&#39;, &#39;OR&#39;, &#39;ORDER&#39;, &#39;OUT&#39;, &#39;OUTER&#39;, &#39;OUTPUTFORMAT&#39;, &#39;OVER&#39;, &#39;OVERLAPS&#39;, &#39;OVERLAY&#39;, &#39;OVERWRITE&#39;, &#39;PARTITION&#39;, &#39;PARTITIONED&#39;, &#39;PARTITIONS&#39;, &#39;PERCENT&#39;, &#39;PIVOT&#39;, &#39;PLACING&#39;, &#39;POSITION&#39;, &#39;PRECEDING&#39;, &#39;PRIMARY&#39;, &#39;PRINCIPALS&#39;, &#39;PROPERTIES&#39;, &#39;PURGE&#39;, &#39;QUERY&#39;, &#39;RANGE&#39;, &#39;RECORDREADER&#39;, &#39;RECORDWRITER&#39;, &#39;RECOVER&#39;, &#39;REDUCE&#39;, &#39;REFERENCES&#39;, &#39;REFRESH&#39;, &#39;RENAME&#39;, &#39;REPAIR&#39;, &#39;REPLACE&#39;, &#39;RESET&#39;, &#39;RESTRICT&#39;, &#39;REVOKE&#39;, &#39;RIGHT&#39;, RLIKE, &#39;ROLE&#39;, &#39;ROLES&#39;, &#39;ROLLBACK&#39;, &#39;ROLLUP&#39;, &#39;ROW&#39;, &#39;ROWS&#39;, &#39;SCHEMA&#39;, &#39;SELECT&#39;, &#39;SEMI&#39;, &#39;SEPARATED&#39;, &#39;SERDE&#39;, &#39;SERDEPROPERTIES&#39;, &#39;SESSION_USER&#39;, &#39;SET&#39;, &#39;MINUS&#39;, &#39;SETS&#39;, &#39;SHOW&#39;, &#39;SKEWED&#39;, &#39;SOME&#39;, &#39;SORT&#39;, &#39;SORTED&#39;, &#39;START&#39;, &#39;STATISTICS&#39;, &#39;STORED&#39;, &#39;STRATIFY&#39;, &#39;STRUCT&#39;, &#39;SUBSTR&#39;, &#39;SUBSTRING&#39;, &#39;TABLE&#39;, &#39;TABLES&#39;, &#39;TABLESAMPLE&#39;, &#39;TBLPROPERTIES&#39;, TEMPORARY, &#39;TERMINATED&#39;, &#39;THEN&#39;, &#39;TO&#39;, &#39;TOUCH&#39;, &#39;TRAILING&#39;, &#39;TRANSACTION&#39;, &#39;TRANSACTIONS&#39;, &#39;TRANSFORM&#39;, &#39;TRIM&#39;, &#39;TRUE&#39;, &#39;TRUNCATE&#39;, &#39;TYPE&#39;, &#39;UNARCHIVE&#39;, &#39;UNBOUNDED&#39;, &#39;UNCACHE&#39;, &#39;UNION&#39;, &#39;UNIQUE&#39;, &#39;UNKNOWN&#39;, &#39;UNLOCK&#39;, &#39;UNSET&#39;, &#39;UPDATE&#39;, &#39;USE&#39;, &#39;USER&#39;, &#39;USING&#39;, &#39;VALUES&#39;, &#39;VIEW&#39;, &#39;VIEWS&#39;, &#39;WHEN&#39;, &#39;WHERE&#39;, &#39;WINDOW&#39;, &#39;WITH&#39;, IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 0)\n\n== SQL ==\n/dbfs/FileStore/tables/avm_output_2021-06-15\n^^^\n</div>"]}}],"execution_count":29}],"metadata":{"kernelspec":{"display_name":"saturn (Python 3)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.10","nbconvert_exporter":"python","file_extension":".py"},"name":"Batch Predict","notebookId":1892563724536844},"nbformat":4,"nbformat_minor":0}